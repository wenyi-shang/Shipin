{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c7cb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819\n"
     ]
    }
   ],
   "source": [
    "# Load the Shipin-poet collection\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open('../Data/Xianqin Han Wei Jin Nanbeichao shi/test_set.json', 'r', encoding='utf-8') as f:\n",
    "    shipin_poet_poems = json.load(f)\n",
    "shipinpoet_poems = []\n",
    "for poet_poems in shipin_poet_poems.values():\n",
    "    for poem in poet_poems:\n",
    "        content = poem.get(\"poem\")\n",
    "        shipinpoet_poems.append(content)\n",
    "\n",
    "total_shipin_poems = len(shipinpoet_poems)\n",
    "print(total_shipin_poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69152815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['扰扰整夜装。肃肃戒徂两。晓星正寥落。晨光复泱漭。犹沾馀露团。稍见朝霞上。故乡邈已敻。山川修且广。文奏方盈前。怀人去心赏。敕躬每跼蹐。瞻恩惟震荡。行矣倦路长。无由税归鞅。',\n",
       " '门有万里客。问君何乡人。褰裳起从之。果得心所亲。挽裳对我泣。太息前自陈。本是朔方士。今为吴越民。行行将复行。去去适西秦。',\n",
       " '昔欲居南村。非为卜其宅。闻多素心人。乐与数晨夕。怀此颇有年。今日从兹役。弊庐何必广。取足蔽床席。邻曲时时来。抗言谈在昔。奇文共欣赏。疑义相与析。春秋多佳日。登高赋新诗。过门更相呼。有酒斟酌之。农务各自归。闲暇辄相思。相思则披衣。言笑无厌时。此理将不胜。无为忽去兹。衣食当须纪。力耕不吾欺。',\n",
       " '豪士枉尺璧。宵人重恩光。狥义非为利。执羁轻去乡。孟冬郊祀月。杀气起严霜。戎马粟不暖。军士冰为浆。晨上城皋坂。碛砾皆羊肠。寒阴笼白日。大谷晦苍苍。息徒税征驾。倚剑临八荒。鹪鹏不能飞。玄武伏川梁。铩翮由时至。感物聊自伤。坚儒守一经。未足识行藏。',\n",
       " '朝云升。应龙攀。乘风远游腾云端。鼓钟歇。岂自欢。急弦高张思和弹。时希值。年夙愆。循己虽易人知难。王阳登。贡公欢。罕生既没国子叹。嗟千载。岂虚言。邈矣远念情忾然。',\n",
       " '微身轻蝉翼。弱冠忝嘉招。在疚妨贤路。再升上宰朝。猥荷公叔举。连陪厕王寮。长啸归江山。拥耒耨时苗。幽谷茂纤葛。峻严敷荣条。落英陨林趾。飞茎秀陵乔。卑高亦何常。升降在一朝。徒恨良时泰。小人道遂消。譬如野田蓬。斡流随风飘。昔倦都邑游。今掌河朔徭。登城眷南顾。凯风扬微绡。洪流何浩荡。修芒郁岧峣。谁谓晋京远。室迩身实辽。谁谓邑宰轻。令名患不劭。人生天地间。百年孰能要。颎如槁石火。瞥若截道飚。齐都无遗声。桐乡有馀谣。福谦在纯约。害盈由矜骄。虽无君人德。视民庶不恌。日夕阴云起。登城望洪河。川气冒山领。惊湍激严阿。归雁暎兰畤。游鱼动圆波。鸣蝉厉寒音。时菊耀秋华。引领望京室。南路在伐柯。大厦缅无觌。崇芒郁嵯峨。总总都邑人。扰扰俗化讹。依水类浮萍。寄松似悬萝。朱博纠舒慢。楚风被琅邪。曲蓬何以直。托身依业麻。黔黎竟何常。政成在民和。位同单父邑。愧无子贱歌。岂敢陋微官。但恐忝所荷。',\n",
       " '举足没泥泞。市道无行车。兰桂贱朽腐。柴粟贵明珠。',\n",
       " '仰彼朔风。用怀魏都。愿骋代马。倏忽北徂。凯风永至。思彼蛮方。愿随越鸟。翻飞南翔。四气代谢。悬景运周。别如俯仰。脱若三秋。昔我初迁。朱华未晞。今我旋止。素雪云飞。俯降千仞。仰登天阻。风飘蓬飞。载离寒暑。千仞易陟。天阻可越。昔我同袍。今永乖别。子好芳草。岂忘尔贻。繁华将茂。秋霜悴之。君不垂眷。岂云其诚。秋兰可喻。桂树冬荣。弦歌荡思。谁与销忧。临川慕思。何为泛舟。岂无和乐。游非我邻。谁忘泛舟。愧无榜人。',\n",
       " '张子暗内机。单生蔽外象。一时排冥筌。冷然空中赏。遣此弱丧情。资神任独往。采药白云隈。聊以肆所养。丹葩曜芳蕤。绿竹阴间敞。苕苕寄意胜。不觉凌虚上。曲棂激鲜飙。石室有幽响。去矣从所欲。得失非外奖。至哉操斤客。重明固已朗。五难既洒落。超迹绝尘网。',\n",
       " '奉辞罚罪遐征。晨过黎山巉峥。东济黄河金营。北观故宅顿倾。中有高楼亭亭。荆棘绕蕃业生。南望果园青青。霜露惨凄宵零。彼桑梓兮伤情。']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select under-510-character poems\n",
    "import random\n",
    "\n",
    "short_shipinpoet_poems = [p for p in shipinpoet_poems if len(p.strip()) <= 510]\n",
    "print(len(short_shipinpoet_poems))\n",
    "random.seed(42)\n",
    "random.sample(short_shipinpoet_poems, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a093cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4496\n"
     ]
    }
   ],
   "source": [
    "# Load the non-Shipin-poet collection\n",
    "with open('../Data/Xianqin Han Wei Jin Nanbeichao shi/train_set.json', 'r', encoding='utf-8') as f:\n",
    "    non_shipin_poet_poems = json.load(f)\n",
    "nonshipinpoet_poems = []\n",
    "for poet_poems in non_shipin_poet_poems.values():\n",
    "    for poem in poet_poems:\n",
    "        content = poem.get(\"poem\")\n",
    "        nonshipinpoet_poems.append(content)\n",
    "\n",
    "total_nonshipin_poems = len(nonshipinpoet_poems)\n",
    "print(total_nonshipin_poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec81f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['百川如镜。天地爽且明。云冲气举。德盛在素精。木叶初下。洞庭始扬波。夜光彻地。翻霜照悬河。庶类收成。岁功行欲宁。浃地奉渥。罄宇承秋灵。',\n",
       " '阎君赋政。既明且昶。去苛去碎。动以礼让。',\n",
       " '弊履常决踵。眉高起半额。曼倩尔何为。独叹长安索。工商既惭巧。农士聊相易。蝘腹有馀资。鸿肩方可拍。摄职愧握兰。滥官悲执戟。连章既不敏。高谈岂能剧。逸翮任奋飞。窘步事羁勒。还鸟余能系。流言尔无惑。忧怀乃千载。永欢常数刻。直是悲别离。非关念通塞。日照汀沙素。山影波浪黑。尔限大江南。余归茂陵北。',\n",
       " '磊磊落落玉山崩。',\n",
       " '停驾望舒移。回轮返沧浪。未睹若人游。偶想安得康。良因俟青春。以叙中怀忘。',\n",
       " '昏主恣淫慝。皆曰自昌盛。上仁矜亿兆。誓师为请命。既齐丹浦战。又符甲子辰。龛难伐有罪。伐罪吊斯民。悠悠亿万姓。於此睹阳春。',\n",
       " '大树转萧索。天阴不作雨。严霜半夜落。折杨柳。林中与松柏。岁寒不相负。',\n",
       " '可怜司马公。作性甚温良。忆昔水边戏。使我不能忘。',\n",
       " '昨晚褰帘望。初逢双燕归。今朝见桃李。不啻数花飞。已愁春欲度。无复寄芳菲。王环',\n",
       " '州郡记。如霹雳。得诏书。但挂壁。']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select under-510-character poems\n",
    "short_non_shipin_poems = [p for p in nonshipinpoet_poems if 0 < len(p.strip()) <= 510]\n",
    "print(len(short_non_shipin_poems))\n",
    "random.seed(42)\n",
    "random.sample(short_non_shipin_poems, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794d2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate Chinese BERT variants \n",
    "model_list = [\"google-bert/bert-base-chinese\",\n",
    "              \"hfl/chinese-macbert-base\",\n",
    "              \"ethanyt/guwenbert-base\",\n",
    "              \"SIKU-BERT/sikubert\",\n",
    "              \"Jihuai/bert-ancient-chinese\",\n",
    "              \"qixun/bert-chinese-poem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363e977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline masked language modeling accuracy for each model\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForMaskedLM,\n",
    ")\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import gc\n",
    "from opencc import OpenCC\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class PoemIterableDataset(IterableDataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "    def __iter__(self):\n",
    "        yield from self.texts\n",
    "\n",
    "def get_punctuation_ids(tokenizer):\n",
    "    ascii_p = list(r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\")\n",
    "    cjk_p = [\"，\",\"。\",\"、\",\"；\",\"？\",\"！\",\"：\",\"“\",\"”\",\"‘\",\"’\",\"（\",\"）\"]\n",
    "    chars = ascii_p + cjk_p\n",
    "    return set(tokenizer.convert_tokens_to_ids([c for c in chars if c in tokenizer.vocab]))\n",
    "\n",
    "def make_collate_fn(tokenizer, punctuation_ids, mlm_prob=0.15):\n",
    "    mask_id = tokenizer.mask_token_id\n",
    "    def collate_fn(batch_texts):\n",
    "        enc = tokenizer(\n",
    "            batch_texts,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512,\n",
    "            return_special_tokens_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        orig_ids = enc[\"input_ids\"].clone()\n",
    "        special_mask = enc[\"special_tokens_mask\"].bool()\n",
    "        punct_ids = torch.tensor(list(punctuation_ids), device=orig_ids.device)\n",
    "        punct_mask = torch.isin(orig_ids, punct_ids)\n",
    "        no_mask = special_mask | punct_mask\n",
    "\n",
    "        labels = orig_ids.clone()\n",
    "        rand = torch.rand(labels.shape)\n",
    "        mask_pos = (rand < mlm_prob) & ~no_mask\n",
    "        labels[~mask_pos] = -100\n",
    "\n",
    "        input_ids = orig_ids.clone()\n",
    "        input_ids[mask_pos] = mask_id\n",
    "\n",
    "        return {\n",
    "            \"texts\": batch_texts,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": enc[\"attention_mask\"],\n",
    "            \"labels\": labels\n",
    "        }\n",
    "    return collate_fn\n",
    "\n",
    "cc = OpenCC('t2s')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a667a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== bert-base-chinese ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd57d5c14cd24008a172fc5d78239aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poem #1 text:\n",
      "径万里兮度沙漠。为君将兮奋匈奴。路穷绝兮矢刃摧。士众灭兮名已隤。老母已死虽欲报恩将安归。\n",
      "  pos   4: real=兮   pred=兮\n",
      "  pos  10: real=君   pred=国\n",
      "  pos  11: real=将   pred=将\n",
      "  pos  14: real=匈   pred=为\n",
      "  pos  30: real=已   pred=将\n",
      "  pos  33: real=老   pred=父\n",
      "  pos  35: real=已   pred=之\n",
      "  pos  40: real=恩   pred=兮\n",
      "  pos  42: real=安   pred=复\n",
      "\n",
      "Poem #2 text:\n",
      "新裂齐纨素。鲜洁如霜雪。裁为合欢扇。团团似明月。出入君怀袖。动摇微风发。常恐秋节至。凉飚夺炎热。弃捐箧笥中。恩情中道绝。\n",
      "  pos   5: real=素   pred=[UNK]\n",
      "  pos  31: real=动   pred=摇\n",
      "  pos  49: real=弃   pred=[UNK]\n",
      "  pos  56: real=情   pred=泽\n",
      "\n",
      "Poem #3 text:\n",
      "於昭明堂。明堂孔阳。圣皇宗祀。穆穆煌煌。上帝宴飨。五位时序。谁其配之。世祖光武。普天率土。各以其职。猗欤缉熙。允怀多福。\n",
      "  pos  18: real=煌   pred=圣\n",
      "  pos  19: real=煌   pred=穆\n",
      "  pos  24: real=飨   pred=飨\n",
      "  pos  38: real=光   pred=文\n",
      "\n",
      "Poem #4 text:\n",
      "乃流辟雍。辟雍汤汤。圣皇莅止。造舟为梁。皤皤国老。乃父乃兄。抑抑威仪。孝友光明。於赫太上。示我汉行。洪化惟神。永观厥成。\n",
      "  pos   1: real=乃   pred=辟\n",
      "  pos   4: real=雍   pred=雍\n",
      "  pos  16: real=造   pred=[UNK]\n",
      "  pos  27: real=父   pred=弟\n",
      "  pos  56: real=永   pred=大\n",
      "\n",
      "Poem #5 text:\n",
      "乃经灵台。灵台既崇。帝勤时登。爰考休徵。三光宣精。五行布序。习习祥风。祁祁甘雨。百谷蓁蓁。庶草蕃庑。屡惟丰年。於皇乐胥。\n",
      "  pos  21: real=三   pred=弘\n",
      "  pos  47: real=草   pred=有\n",
      "  pos  51: real=屡   pred=于\n",
      "  pos  52: real=惟   pred=[UNK]\n",
      "  pos  58: real=乐   pred=[UNK]\n",
      "bert-base-chinese simplified-normalized MLM accuracy: 0.1287\n",
      "\n",
      "=== chinese-macbert-base ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-macbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95fa1ff255b40819f999b8d40816a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poem #1 text:\n",
      "径万里兮度沙漠。为君将兮奋匈奴。路穷绝兮矢刃摧。士众灭兮名已隤。老母已死虽欲报恩将安归。\n",
      "  pos   5: real=度   pred=金\n",
      "  pos   7: real=漠   pred=漠\n",
      "  pos   9: real=为   pred=将\n",
      "  pos  10: real=君   pred=千\n",
      "  pos  13: real=奋   pred=战\n",
      "  pos  25: real=士   pred=将\n",
      "  pos  28: real=兮   pred=兮\n",
      "  pos  35: real=已   pred=之\n",
      "  pos  40: real=恩   pred=兮\n",
      "  pos  41: real=将   pred=亦\n",
      "\n",
      "Poem #2 text:\n",
      "新裂齐纨素。鲜洁如霜雪。裁为合欢扇。团团似明月。出入君怀袖。动摇微风发。常恐秋节至。凉飚夺炎热。弃捐箧笥中。恩情中道绝。\n",
      "  pos  17: real=扇   pred=歌\n",
      "  pos  21: real=似   pred=如\n",
      "  pos  37: real=常   pred=惊\n",
      "  pos  47: real=热   pred=热\n",
      "  pos  56: real=情   pred=[UNK]\n",
      "  pos  58: real=道   pred=不\n",
      "\n",
      "Poem #3 text:\n",
      "於昭明堂。明堂孔阳。圣皇宗祀。穆穆煌煌。上帝宴飨。五位时序。谁其配之。世祖光武。普天率土。各以其职。猗欤缉熙。允怀多福。\n",
      "  pos  12: real=皇   pred=宗\n",
      "  pos  24: real=飨   pred=之\n",
      "  pos  39: real=武   pred=明\n",
      "  pos  48: real=其   pred=其\n",
      "\n",
      "Poem #4 text:\n",
      "乃流辟雍。辟雍汤汤。圣皇莅止。造舟为梁。皤皤国老。乃父乃兄。抑抑威仪。孝友光明。於赫太上。示我汉行。洪化惟神。永观厥成。\n",
      "  pos  19: real=梁   pred=舟\n",
      "  pos  24: real=老   pred=[UNK]\n",
      "  pos  43: real=太   pred=天\n",
      "  pos  53: real=惟   pred=之\n",
      "\n",
      "Poem #5 text:\n",
      "乃经灵台。灵台既崇。帝勤时登。爰考休徵。三光宣精。五行布序。习习祥风。祁祁甘雨。百谷蓁蓁。庶草蕃庑。屡惟丰年。於皇乐胥。\n",
      "  pos   4: real=台   pred=台\n",
      "  pos   9: real=崇   pred=立\n",
      "  pos  54: real=年   pred=[UNK]\n",
      "chinese-macbert-base simplified-normalized MLM accuracy: 0.0906\n",
      "\n",
      "=== guwenbert-base ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ethanyt/guwenbert-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca11d49df10f426ea42d7d8bfba0106a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poem #1 text:\n",
      "径万里兮度沙漠。为君将兮奋匈奴。路穷绝兮矢刃摧。士众灭兮名已隤。老母已死虽欲报恩将安归。\n",
      "  pos  13: real=奋   pred=征\n",
      "  pos  15: real=奴   pred=奴\n",
      "  pos  31: real=[UNK]   pred=亏\n",
      "  pos  33: real=老   pred=[SEP]\n",
      "  pos  35: real=已   pred=已\n",
      "  pos  39: real=报   pred=报\n",
      "\n",
      "Poem #2 text:\n",
      "新裂齐纨素。鲜洁如霜雪。裁为合欢扇。团团似明月。出入君怀袖。动摇微风发。常恐秋节至。凉飚夺炎热。弃捐箧笥中。恩情中道绝。\n",
      "  pos  20: real=团   pred=光\n",
      "  pos  22: real=明   pred=明\n",
      "  pos  26: real=入   pred=入\n",
      "  pos  27: real=君   pred=君\n",
      "  pos  38: real=恐   pred=恐\n",
      "  pos  41: real=至   pred=至\n",
      "  pos  49: real=弃   pred=[SEP]\n",
      "  pos  51: real=箧   pred=箧\n",
      "\n",
      "Poem #3 text:\n",
      "於昭明堂。明堂孔阳。圣皇宗祀。穆穆煌煌。上帝宴飨。五位时序。谁其配之。世祖光武。普天率土。各以其职。猗欤缉熙。允怀多福。\n",
      "  pos   2: real=昭   pred=乎\n",
      "  pos   9: real=阳   pred=阳\n",
      "  pos  26: real=五   pred=[SEP]\n",
      "  pos  28: real=时   pred=以\n",
      "  pos  29: real=序   pred=方\n",
      "  pos  46: real=各   pred=[SEP]\n",
      "  pos  48: real=其   pred=臣\n",
      "\n",
      "Poem #4 text:\n",
      "乃流辟雍。辟雍汤汤。圣皇莅止。造舟为梁。皤皤国老。乃父乃兄。抑抑威仪。孝友光明。於赫太上。示我汉行。洪化惟神。永观厥成。\n",
      "  pos   3: real=辟   pred=辟\n",
      "  pos  22: real=皤   pred=惟\n",
      "  pos  41: real=于   pred=[SEP]\n",
      "  pos  46: real=示   pred=[SEP]\n",
      "  pos  47: real=我   pred=江\n",
      "  pos  51: real=洪   pred=[SEP]\n",
      "\n",
      "Poem #5 text:\n",
      "乃经灵台。灵台既崇。帝勤时登。爰考休徵。三光宣精。五行布序。习习祥风。祁祁甘雨。百谷蓁蓁。庶草蕃庑。屡惟丰年。於皇乐胥。\n",
      "  pos   3: real=灵   pred=灵\n",
      "  pos   4: real=台   pred=台\n",
      "  pos  11: real=帝   pred=[SEP]\n",
      "  pos  21: real=三   pred=[SEP]\n",
      "  pos  22: real=光   pred=观\n",
      "  pos  23: real=宣   pred=时\n",
      "  pos  24: real=精   pred=征\n",
      "  pos  29: real=序   pred=政\n",
      "  pos  32: real=习   pred=习\n",
      "  pos  52: real=惟   pred=屡\n",
      "  pos  57: real=皇   pred=乎\n",
      "guwenbert-base simplified-normalized MLM accuracy: 0.2821\n",
      "\n",
      "=== sikubert ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SIKU-BERT/sikubert were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2126edf74494404788195e3a5fd56eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poem #1 text:\n",
      "径万里兮度沙漠。为君将兮奋匈奴。路穷绝兮矢刃摧。士众灭兮名已隤。老母已死虽欲报恩将安归。\n",
      "  pos   7: real=漠   pred=漠\n",
      "  pos   9: real=为   pred=为\n",
      "  pos  14: real=匈   pred=匈\n",
      "  pos  27: real=灭   pred=多\n",
      "  pos  42: real=安   pred=何\n",
      "\n",
      "Poem #2 text:\n",
      "新裂齐纨素。鲜洁如霜雪。裁为合欢扇。团团似明月。出入君怀袖。动摇微风发。常恐秋节至。凉飚夺炎热。弃捐箧笥中。恩情中道绝。\n",
      "  pos  15: real=合   pred=合\n",
      "  pos  27: real=君   pred=我\n",
      "  pos  31: real=动   pred=凉\n",
      "  pos  32: real=摇   pred=有\n",
      "  pos  37: real=常   pred=只\n",
      "  pos  57: real=中   pred=天\n",
      "\n",
      "Poem #3 text:\n",
      "於昭明堂。明堂孔阳。圣皇宗祀。穆穆煌煌。上帝宴飨。五位时序。谁其配之。世祖光武。普天率土。各以其职。猗欤缉熙。允怀多福。\n",
      "  pos  21: real=上   pred=皇\n",
      "  pos  42: real=天   pred=天\n",
      "  pos  43: real=率   pred=普\n",
      "  pos  47: real=以   pred=有\n",
      "  pos  48: real=其   pred=其\n",
      "  pos  51: real=猗   pred=熙\n",
      "  pos  59: real=福   pred=士\n",
      "\n",
      "Poem #4 text:\n",
      "乃流辟雍。辟雍汤汤。圣皇莅止。造舟为梁。皤皤国老。乃父乃兄。抑抑威仪。孝友光明。於赫太上。示我汉行。洪化惟神。永观厥成。\n",
      "  pos   1: real=乃   pred=雍\n",
      "  pos   9: real=汤   pred=辟\n",
      "  pos  12: real=皇   pred=人\n",
      "  pos  13: real=莅   pred=圣\n",
      "  pos  14: real=止   pred=圣\n",
      "  pos  26: real=乃   pred=父\n",
      "  pos  27: real=父   pred=弟\n",
      "  pos  28: real=乃   pred=父\n",
      "  pos  32: real=抑   pred=抑\n",
      "  pos  39: real=明   pred=天\n",
      "  pos  49: real=行   pred=书\n",
      "  pos  51: real=洪   pred=厥\n",
      "  pos  54: real=神   pred=天\n",
      "  pos  56: real=永   pred=人\n",
      "\n",
      "Poem #5 text:\n",
      "乃经灵台。灵台既崇。帝勤时登。爰考休徵。三光宣精。五行布序。习习祥风。祁祁甘雨。百谷蓁蓁。庶草蕃庑。屡惟丰年。於皇乐胥。\n",
      "  pos   2: real=经   pred=登\n",
      "  pos   3: real=灵   pred=三\n",
      "  pos   7: real=台   pred=祇\n",
      "  pos  17: real=考   pred=发\n",
      "  pos  21: real=三   pred=以\n",
      "  pos  33: real=祥   pred=凉\n",
      "  pos  37: real=祁   pred=祁\n",
      "  pos  51: real=屡   pred=年\n",
      "  pos  56: real=于   pred=永\n",
      "sikubert simplified-normalized MLM accuracy: 0.1465\n",
      "\n",
      "=== bert-ancient-chinese ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607bc3bd1736494498a80097320b04d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poem #1 text:\n",
      "径万里兮度沙漠。为君将兮奋匈奴。路穷绝兮矢刃摧。士众灭兮名已隤。老母已死虽欲报恩将安归。\n",
      "  pos   2: real=万   pred=君\n",
      "  pos   3: real=里   pred=马\n",
      "  pos   6: real=沙   pred=沙\n",
      "  pos  11: real=将   pred=子\n",
      "  pos  14: real=匈   pred=匈\n",
      "  pos  26: real=众   pred=气\n",
      "  pos  30: real=已   pred=已\n",
      "  pos  38: real=欲   pred=。\n",
      "\n",
      "Poem #2 text:\n",
      "新裂齐纨素。鲜洁如霜雪。裁为合欢扇。团团似明月。出入君怀袖。动摇微风发。常恐秋节至。凉飚夺炎热。弃捐箧笥中。恩情中道绝。\n",
      "  pos   1: real=新   pred=我\n",
      "  pos   2: real=裂   pred=衣\n",
      "  pos   3: real=齐   pred=如\n",
      "  pos  10: real=霜   pred=霜\n",
      "  pos  13: real=裁   pred=轻\n",
      "  pos  15: real=合   pred=如\n",
      "  pos  19: real=团   pred=皎\n",
      "  pos  26: real=入   pred=入\n",
      "  pos  28: real=怀   pred=怀\n",
      "  pos  32: real=摇   pred=之\n",
      "  pos  33: real=微   pred=君\n",
      "  pos  39: real=秋   pred=寒\n",
      "  pos  45: real=夺   pred=避\n",
      "  pos  50: real=捐   pred=置\n",
      "  pos  55: real=恩   pred=不\n",
      "  pos  56: real=情   pred=之\n",
      "\n",
      "Poem #3 text:\n",
      "於昭明堂。明堂孔阳。圣皇宗祀。穆穆煌煌。上帝宴飨。五位时序。谁其配之。世祖光武。普天率土。各以其职。猗欤缉熙。允怀多福。\n",
      "  pos   6: real=明   pred=明\n",
      "  pos  12: real=皇   pred=穆\n",
      "  pos  17: real=穆   pred=穆\n",
      "  pos  32: real=其   pred=祖\n",
      "  pos  48: real=其   pred=其\n",
      "  pos  53: real=缉   pred=缉\n",
      "  pos  59: real=福   pred=祜\n",
      "\n",
      "Poem #4 text:\n",
      "乃流辟雍。辟雍汤汤。圣皇莅止。造舟为梁。皤皤国老。乃父乃兄。抑抑威仪。孝友光明。於赫太上。示我汉行。洪化惟神。永观厥成。\n",
      "  pos  13: real=莅   pred=之\n",
      "  pos  14: real=止   pred=皇\n",
      "  pos  17: real=舟   pred=舟\n",
      "  pos  23: real=国   pred=老\n",
      "  pos  24: real=老   pred=父\n",
      "  pos  27: real=父   pred=父\n",
      "  pos  32: real=抑   pred=抑\n",
      "  pos  34: real=仪   pred=仪\n",
      "  pos  37: real=友   pred=道\n",
      "  pos  42: real=赫   pred=赫\n",
      "\n",
      "Poem #5 text:\n",
      "乃经灵台。灵台既崇。帝勤时登。爰考休徵。三光宣精。五行布序。习习祥风。祁祁甘雨。百谷蓁蓁。庶草蕃庑。屡惟丰年。於皇乐胥。\n",
      "  pos   2: real=经   pred=登\n",
      "  pos   3: real=灵   pred=天\n",
      "  pos   9: real=崇   pred=成\n",
      "  pos  19: real=征   pred=征\n",
      "  pos  22: real=光   pred=光\n",
      "  pos  24: real=精   pred=化\n",
      "  pos  27: real=行   pred=云\n",
      "  pos  29: real=序   pred=和\n",
      "  pos  38: real=甘   pred=甘\n",
      "  pos  46: real=庶   pred=庶\n",
      "  pos  49: real=[UNK]   pred=庑\n",
      "  pos  51: real=屡   pred=时\n",
      "  pos  57: real=皇   pred=乐\n",
      "bert-ancient-chinese simplified-normalized MLM accuracy: 0.1815\n",
      "\n",
      "=== bert-chinese-poem ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab64db39acf04862838f726b83a21fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poem #1 text:\n",
      "径万里兮度沙漠。为君将兮奋匈奴。路穷绝兮矢刃摧。士众灭兮名已隤。老母已死虽欲报恩将安归。\n",
      "  pos   3: real=里   pred=里\n",
      "  pos   9: real=为   pred=奉\n",
      "  pos  13: real=奋   pred=封\n",
      "  pos  31: real=[UNK]   pred=违\n",
      "  pos  42: real=安   pred=安\n",
      "\n",
      "Poem #2 text:\n",
      "新裂齐纨素。鲜洁如霜雪。裁为合欢扇。团团似明月。出入君怀袖。动摇微风发。常恐秋节至。凉飚夺炎热。弃捐箧笥中。恩情中道绝。\n",
      "  pos   9: real=如   pred=如\n",
      "  pos  19: real=团   pred=团\n",
      "  pos  28: real=怀   pred=王\n",
      "  pos  58: real=道   pred=断\n",
      "\n",
      "Poem #3 text:\n",
      "於昭明堂。明堂孔阳。圣皇宗祀。穆穆煌煌。上帝宴飨。五位时序。谁其配之。世祖光武。普天率土。各以其职。猗欤缉熙。允怀多福。\n",
      "  pos  37: real=祖   pred=有\n",
      "  pos  49: real=职   pred=序\n",
      "\n",
      "Poem #4 text:\n",
      "乃流辟雍。辟雍汤汤。圣皇莅止。造舟为梁。皤皤国老。乃父乃兄。抑抑威仪。孝友光明。於赫太上。示我汉行。洪化惟神。永观厥成。\n",
      "  pos   6: real=辟   pred=肃\n",
      "  pos   8: real=汤   pred=汤\n",
      "  pos  21: real=皤   pred=皤\n",
      "  pos  27: real=父   pred=祖\n",
      "\n",
      "Poem #5 text:\n",
      "乃经灵台。灵台既崇。帝勤时登。爰考休徵。三光宣精。五行布序。习习祥风。祁祁甘雨。百谷蓁蓁。庶草蕃庑。屡惟丰年。於皇乐胥。\n",
      "  pos   6: real=灵   pred=灵\n",
      "  pos   8: real=既   pred=既\n",
      "  pos  12: real=勤   pred=宫\n",
      "  pos  23: real=宣   pred=降\n",
      "  pos  27: real=行   pred=行\n",
      "  pos  28: real=布   pred=交\n",
      "  pos  43: real=蓁   pred=咸\n",
      "  pos  44: real=蓁   pred=圃\n",
      "  pos  58: real=乐   pred=乐\n",
      "bert-chinese-poem simplified-normalized MLM accuracy: 0.1639\n"
     ]
    }
   ],
   "source": [
    "for embedding_model in model_list:\n",
    "    model_name = embedding_model.split(\"/\")[-1]\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(embedding_model)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(embedding_model).to(device).eval()\n",
    "\n",
    "    test_ds = PoemIterableDataset(short_shipinpoet_poems)\n",
    "    punctuation_ids = get_punctuation_ids(tokenizer)\n",
    "    collate_fn = make_collate_fn(tokenizer, punctuation_ids)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=8,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    total, correct = 0, 0\n",
    "    poems_printed = 0\n",
    "    PRINT_LIMIT = 5\n",
    "\n",
    "    for batch in tqdm(test_loader, desc=\"Batches\", unit=\"batch\"):\n",
    "        texts = batch[\"texts\"]\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "        preds = logits.argmax(dim=-1)\n",
    "\n",
    "        for i in range(input_ids.size(0)):\n",
    "            masked_positions = (labels[i] != -100).nonzero(as_tuple=True)[0].tolist()\n",
    "            for pos in masked_positions:\n",
    "                real_tok = tokenizer.convert_ids_to_tokens([int(labels[i,pos])])[0]\n",
    "                pred_tok = tokenizer.convert_ids_to_tokens([int(preds[i,pos])])[0]\n",
    "                if cc.convert(real_tok) == cc.convert(pred_tok):\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "            if poems_printed < PRINT_LIMIT and masked_positions:\n",
    "                print(f\"\\nPoem #{poems_printed+1} text:\\n{texts[i]}\")\n",
    "                for pos in masked_positions:\n",
    "                    real_s = cc.convert(tokenizer.convert_ids_to_tokens([int(labels[i,pos])])[0])\n",
    "                    pred_s = cc.convert(tokenizer.convert_ids_to_tokens([int(preds[i,pos])])[0])\n",
    "                    print(f\"  pos {pos:3d}: real={real_s}   pred={pred_s}\")\n",
    "                poems_printed += 1\n",
    "\n",
    "    overall_acc = correct / total if total else 0.0\n",
    "    print(f\"{model_name} simplified-normalized MLM accuracy: {overall_acc:.4f}\")\n",
    "\n",
    "    del model, tokenizer, test_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af7c284c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fine-tuned Guwenbert-base ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a99ade1a4554f6fbed719ca8c4d3258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poem #1 text:\n",
      "径万里兮度沙漠。为君将兮奋匈奴。路穷绝兮矢刃摧。士众灭兮名已隤。老母已死虽欲报恩将安归。\n",
      "  pos   1: real=径   pred=行\n",
      "  pos   4: real=兮   pred=兮\n",
      "  pos  26: real=众   pred=已\n",
      "  pos  35: real=已   pred=已\n",
      "  pos  37: real=虽   pred=兮\n",
      "  pos  39: real=报   pred=报\n",
      "\n",
      "Poem #2 text:\n",
      "新裂齐纨素。鲜洁如霜雪。裁为合欢扇。团团似明月。出入君怀袖。动摇微风发。常恐秋节至。凉飚夺炎热。弃捐箧笥中。恩情中道绝。\n",
      "  pos   5: real=素   pred=素\n",
      "  pos  17: real=扇   pred=扇\n",
      "  pos  19: real=团   pred=团\n",
      "  pos  35: real=发   pred=发\n",
      "  pos  40: real=节   pred=节\n",
      "  pos  46: real=炎   pred=炎\n",
      "  pos  57: real=中   pred=谁\n",
      "  pos  59: real=绝   pred=绝\n",
      "\n",
      "Poem #3 text:\n",
      "於昭明堂。明堂孔阳。圣皇宗祀。穆穆煌煌。上帝宴飨。五位时序。谁其配之。世祖光武。普天率土。各以其职。猗欤缉熙。允怀多福。\n",
      "  pos   2: real=昭   pred=赫\n",
      "  pos   4: real=堂   pred=堂\n",
      "  pos  19: real=煌   pred=煌\n",
      "  pos  34: real=之   pred=之\n",
      "  pos  38: real=光   pred=文\n",
      "  pos  54: real=熙   pred=熙\n",
      "\n",
      "Poem #4 text:\n",
      "乃流辟雍。辟雍汤汤。圣皇莅止。造舟为梁。皤皤国老。乃父乃兄。抑抑威仪。孝友光明。於赫太上。示我汉行。洪化惟神。永观厥成。\n",
      "  pos   2: real=流   pred=营\n",
      "  pos   4: real=雍   pred=雍\n",
      "  pos  27: real=父   pred=肃\n",
      "  pos  29: real=兄   pred=耕\n",
      "  pos  34: real=仪   pred=仪\n",
      "  pos  46: real=示   pred=光\n",
      "\n",
      "Poem #5 text:\n",
      "乃经灵台。灵台既崇。帝勤时登。爰考休徵。三光宣精。五行布序。习习祥风。祁祁甘雨。百谷蓁蓁。庶草蕃庑。屡惟丰年。於皇乐胥。\n",
      "  pos   4: real=台   pred=坛\n",
      "  pos   7: real=台   pred=坛\n",
      "  pos  21: real=三   pred=三\n",
      "  pos  23: real=宣   pred=降\n",
      "  pos  26: real=五   pred=五\n",
      "  pos  39: real=雨   pred=雨\n",
      "  pos  46: real=庶   pred=庶\n",
      "Fine-tuned Guwenbert-base simplified-normalized MLM accuracy: 0.3522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate masked language modeling accuracy for the fine-tuned Guwenbert model\n",
    "model_name = \"Fine-tuned Guwenbert-base\"\n",
    "print(f\"\\n=== {model_name} ===\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained((\"../Models/fine-tuned-best_lr1e-05_bs32\"))\n",
    "model = AutoModelForMaskedLM.from_pretrained((\"../Models/fine-tuned-best_lr1e-05_bs32\")).to(device).eval()\n",
    "\n",
    "test_ds = PoemIterableDataset(short_shipinpoet_poems)\n",
    "punctuation_ids = get_punctuation_ids(tokenizer)\n",
    "collate_fn = make_collate_fn(tokenizer, punctuation_ids)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=8,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "total, correct = 0, 0\n",
    "poems_printed = 0\n",
    "PRINT_LIMIT = 5\n",
    "\n",
    "for batch in tqdm(test_loader, desc=\"Batches\", unit=\"batch\"):\n",
    "    texts = batch[\"texts\"]\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "    preds = logits.argmax(dim=-1)\n",
    "\n",
    "    for i in range(input_ids.size(0)):\n",
    "        masked_positions = (labels[i] != -100).nonzero(as_tuple=True)[0].tolist()\n",
    "        for pos in masked_positions:\n",
    "            real_tok = tokenizer.convert_ids_to_tokens([int(labels[i,pos])])[0]\n",
    "            pred_tok = tokenizer.convert_ids_to_tokens([int(preds[i,pos])])[0]\n",
    "            if cc.convert(real_tok) == cc.convert(pred_tok):\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "        if poems_printed < PRINT_LIMIT and masked_positions:\n",
    "            print(f\"\\nPoem #{poems_printed+1} text:\\n{texts[i]}\")\n",
    "            for pos in masked_positions:\n",
    "                real_s = cc.convert(tokenizer.convert_ids_to_tokens([int(labels[i,pos])])[0])\n",
    "                pred_s = cc.convert(tokenizer.convert_ids_to_tokens([int(preds[i,pos])])[0])\n",
    "                print(f\"  pos {pos:3d}: real={real_s}   pred={pred_s}\")\n",
    "            poems_printed += 1\n",
    "\n",
    "overall_acc = correct / total if total else 0.0\n",
    "print(f\"{model_name} simplified-normalized MLM accuracy: {overall_acc:.4f}\")\n",
    "\n",
    "del model, tokenizer, test_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
